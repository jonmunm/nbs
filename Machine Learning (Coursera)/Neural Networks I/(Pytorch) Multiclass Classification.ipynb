{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('ex3data1.mat')\n",
    "x, y = torch.tensor(data['X']), torch.tensor(data['y']).T\n",
    "M = y.shape[1]\n",
    "\n",
    "\n",
    "# Agrega los 1's en columnas\n",
    "X = torch.cat((torch.ones(M, 1), x), 1)\n",
    "N = X.shape[1]\n",
    "K = len(torch.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1 / (1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunctionReg(X, y, M, N, initial_theta, lambda_):\n",
    "    h = sigmoid(torch.mm(initial_theta, X.T))\n",
    "    reg_cost = torch.square(initial_theta[:,1:]).sum() * lambda_ / (2 * M)\n",
    "    reg_grad = torch.tensor([0 if i == 0 else initial_theta[:,i] for i in range(N)]) * lambda_\n",
    "\n",
    "    J = (-torch.mm(torch.log(h), y.T) - torch.mm(torch.log(1 - h), (1 - y).T))/M + reg_cost\n",
    "    grad = (torch.mm(X.T, (h - y).T).T + reg_grad)/M\n",
    "\n",
    "    return J.item(), grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_test = 3\n",
    "M_test = 5\n",
    "N_test = 4\n",
    "theta_test = torch.tensor([[-2., -1., 1., 2.]])\n",
    "X_test = torch.cat((torch.ones(1, 5), torch.tensor([[1.,2.,3.,4.,5], [6.,7.,8.,9.,10.], [11.,12.,13.,14.,15.]])/10)).T\n",
    "y_test = torch.tensor([[1., 0., 1., 0., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5348193961097443, tensor([[ 0.1466, -0.5486,  0.7247,  1.3980]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J, grad = costFunctionReg(X_test, y_test, M_test, N_test, theta_test, lambda_test)\n",
    "J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-vs-all Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 5000\n",
    "lambda_ = .1\n",
    "alpha = .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, M, N, initial_theta, alpha, lambda_, iterations):\n",
    "    theta = initial_theta.clone()\n",
    "    for i in range(0, iterations):\n",
    "        _, grad = costFunctionReg(X, y, M, N, theta, lambda_)\n",
    "        theta -= alpha * grad\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAll(X, y, K):\n",
    "\n",
    "    theta_0 = torch.zeros(1, N)\n",
    "    all_theta = []\n",
    "    \n",
    "    for k in range(1, K + 1):\n",
    "        theta = gradientDescent(X, (y == k).type(torch.double), M, N, theta_0, alpha, lambda_, iterations)\n",
    "        all_theta.append(theta[0].numpy())\n",
    "        \n",
    "    return torch.tensor(all_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_theta = oneVsAll(X, y, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, initial_theta):\n",
    "    return sigmoid(torch.mm(initial_theta, X.T)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(X, all_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, y):\n",
    "    selected_y = torch.argmax(predictions, dim=1) + 1\n",
    "    return (selected_y == y).type(torch.double).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predictions, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
